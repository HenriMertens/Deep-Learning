{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD, AdamW\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import zipfile\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as pi_efficient\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as pi_resnet\n",
    "\n",
    "from tensorflow.keras import layers, models, preprocessing\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path         label\n",
      "0  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "1  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "2  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "3  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "4  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "                                          image_path         label\n",
      "0  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "1  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "2  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "3  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "4  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "                                          image_path         label\n",
      "0  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "1  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "2  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "3  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "4  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "                                          image_path         label\n",
      "0  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "1  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "2  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "3  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "4  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "                                          image_path         label\n",
      "0  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "1  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "2  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "3  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n",
      "4  c:\\Users\\Henri\\Downloads\\Henri\\Master HIR\\Vakk...  bart_simpson\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "train_path = os.path.join(base_dir, \"simpsons-mnist-master\", \"dataset\", \"rgb\", \"train\")\n",
    "test_path = os.path.join(base_dir, \"simpsons-mnist-master\", \"dataset\", \"rgb\", \"test\")\n",
    "test_rotated_path = os.path.join(base_dir, \"simpsons-mnist-master\", \"dataset\", \"rgb\", \"test_rotated\")\n",
    "test_zoomed_in_path = os.path.join(base_dir, \"simpsons-mnist-master\", \"dataset\", \"rgb\", \"test_zoomed_in\")\n",
    "test_zoomed_out_path = os.path.join(base_dir, \"simpsons-mnist-master\", \"dataset\", \"rgb\", \"test_zoomed_out\")\n",
    "\n",
    "image_data = []\n",
    "test_data = []\n",
    "test_r_data = []\n",
    "test_zi_data = []\n",
    "test_zo_data = []\n",
    "\n",
    "for class_name in os.listdir(train_path):\n",
    "\n",
    "    class_path = os.path.join(train_path, class_name)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        for img_name in os.listdir(class_path):\n",
    "            image_data.append((os.path.join(class_path, img_name), class_name))\n",
    "\n",
    "df_train = pd.DataFrame(image_data, columns=[\"image_path\", \"label\"])\n",
    "print(df_train.head())\n",
    "\n",
    "for class_name in os.listdir(test_path):\n",
    "\n",
    "    class_path = os.path.join(test_path, class_name)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        for img_name in os.listdir(class_path):\n",
    "            test_data.append((os.path.join(class_path, img_name), class_name))\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame(test_data, columns=[\"image_path\", \"label\"])\n",
    "print(df_test.head())\n",
    "\n",
    "for class_name in os.listdir(test_rotated_path):\n",
    "\n",
    "    class_path = os.path.join(test_rotated_path, class_name)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        for img_name in os.listdir(class_path):\n",
    "            test_r_data.append((os.path.join(class_path, img_name), class_name))\n",
    "\n",
    "df_test_r = pd.DataFrame(test_r_data, columns=[\"image_path\", \"label\"])\n",
    "print(df_test_r.head())\n",
    "\n",
    "for class_name in os.listdir(test_zoomed_in_path):\n",
    "\n",
    "    class_path = os.path.join(test_zoomed_in_path, class_name)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        for img_name in os.listdir(class_path):\n",
    "            test_zi_data.append((os.path.join(class_path, img_name), class_name))\n",
    "\n",
    "df_test_zi = pd.DataFrame(test_zi_data, columns=[\"image_path\", \"label\"])\n",
    "print(df_test_zi.head())\n",
    "\n",
    "for class_name in os.listdir(test_zoomed_out_path):\n",
    "\n",
    "    class_path = os.path.join(test_zoomed_out_path, class_name)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        for img_name in os.listdir(class_path):\n",
    "            test_zo_data.append((os.path.join(class_path, img_name), class_name))\n",
    "\n",
    "df_test_zo = pd.DataFrame(test_zo_data, columns=[\"image_path\", \"label\"])\n",
    "print(df_test_zo.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "\n",
    "df_train[\"image_array\"] = df_train[\"image_path\"].apply(lambda x: load_image(x))\n",
    "\n",
    "df_test[\"image_array\"] = df_test[\"image_path\"].apply(lambda x: load_image(x))\n",
    "\n",
    "df_test_r[\"image_array\"] = df_test_r[\"image_path\"].apply(lambda x: load_image(x))\n",
    "\n",
    "df_test_zi[\"image_array\"] = df_test_zi[\"image_path\"].apply(lambda x: load_image(x))\n",
    "\n",
    "df_test_zo[\"image_array\"] = df_test_zo[\"image_path\"].apply(lambda x: load_image(x))\n",
    "\n",
    "\n",
    "sample_img = df_train[\"image_array\"][0]\n",
    "print(sample_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "num_classes = df_train.label.nunique()\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 28, 28, 3)\n",
      "(8000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_train[\"label_encoded\"] = label_encoder.fit_transform(df_train[\"label\"])\n",
    "df_test[\"label_encoded\"] = label_encoder.transform(df_test[\"label\"])\n",
    "df_test_r[\"label_encoded\"] = label_encoder.transform(df_test_r[\"label\"])\n",
    "df_test_zi[\"label_encoded\"] = label_encoder.transform(df_test_zi[\"label\"])\n",
    "df_test_zo[\"label_encoded\"] = label_encoder.transform(df_test_zo[\"label\"])\n",
    "\n",
    "\n",
    "\n",
    "X_train_valid = np.stack(df_train[\"image_array\"].values)\n",
    "\n",
    "\n",
    "y_train_valid = to_categorical(df_train[\"label_encoded\"], num_classes=num_classes)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.3, random_state=42)\n",
    "\n",
    "X_test = np.stack(df_test[\"image_array\"].values)\n",
    "y_test = to_categorical(df_test[\"label_encoded\"], num_classes=num_classes)\n",
    "\n",
    "X_test_r = np.stack(df_test_r[\"image_array\"].values)\n",
    "y_test_r = to_categorical(df_test_r[\"label_encoded\"], num_classes=num_classes)\n",
    "\n",
    "X_test_zi = np.stack(df_test_zi[\"image_array\"].values)\n",
    "y_test_zi = to_categorical(df_test_zi[\"label_encoded\"], num_classes=num_classes)\n",
    "\n",
    "X_test_zo = np.stack(df_test_zo[\"image_array\"].values)\n",
    "y_test_zo = to_categorical(df_test_zo[\"label_encoded\"], num_classes=num_classes)\n",
    "\n",
    "\n",
    "print(X_train_valid.shape)\n",
    "print(y_train_valid.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Preprocess all images of entire dataset\n",
    "X_train = pi_resnet(X_train)\n",
    "X_valid = pi_resnet(X_valid)\n",
    "\n",
    "X_train_resized = tf.image.resize(X_train, (32, 32))\n",
    "X_valid_resized = tf.image.resize(X_valid, (32, 32))\n",
    "\n",
    "# Import ResNet50 for transfer learning\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "base_model.trainable = False  # Freeze base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "data_augmentation = models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "    #layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "custom_cnn = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(3, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "])\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    custom_cnn,          \n",
    "    base_model,                 \n",
    "    layers.GlobalAveragePooling2D(),        \n",
    "    layers.Dense(256),        \n",
    "    layers.LeakyReLU(alpha=0.3),   \n",
    "    layers.Dropout(0.3),        \n",
    "    layers.Dense(128),         \n",
    "    layers.LeakyReLU(alpha=0.3),   \n",
    "    layers.Dropout(0.2),       \n",
    "    layers.Dense(num_classes, activation='softmax')  \n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_resized shape: (5600, 32, 32, 3)\n",
      "y_train shape: (5600, 10)\n",
      "X_valid_resized shape: (2400, 32, 32, 3)\n",
      "y_valid shape: (2400, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train_resized shape: {X_train_resized.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_valid_resized shape: {X_valid_resized.shape}\")\n",
    "print(f\"y_valid shape: {y_valid.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "88/88 [==============================] - 130s 1s/step - loss: 2.4354 - accuracy: 0.0962 - val_loss: 2.3298 - val_accuracy: 0.0967\n",
      "Epoch 2/1000\n",
      "88/88 [==============================] - 122s 1s/step - loss: 2.3472 - accuracy: 0.0913 - val_loss: 2.3129 - val_accuracy: 0.1004\n",
      "Epoch 3/1000\n",
      "88/88 [==============================] - 119s 1s/step - loss: 2.3391 - accuracy: 0.0975 - val_loss: 2.3257 - val_accuracy: 0.0996\n",
      "Epoch 4/1000\n",
      "88/88 [==============================] - 126s 1s/step - loss: 2.3366 - accuracy: 0.1011 - val_loss: 2.3102 - val_accuracy: 0.1042\n",
      "Epoch 5/1000\n",
      "88/88 [==============================] - 121s 1s/step - loss: 2.3272 - accuracy: 0.1039 - val_loss: 2.3367 - val_accuracy: 0.0867\n",
      "Epoch 6/1000\n",
      "88/88 [==============================] - 131s 1s/step - loss: 2.3240 - accuracy: 0.1021 - val_loss: 2.3142 - val_accuracy: 0.0967\n",
      "Epoch 7/1000\n",
      "88/88 [==============================] - 126s 1s/step - loss: 2.3246 - accuracy: 0.0989 - val_loss: 2.3065 - val_accuracy: 0.0983\n",
      "Epoch 8/1000\n",
      "88/88 [==============================] - 120s 1s/step - loss: 2.3236 - accuracy: 0.0945 - val_loss: 2.3124 - val_accuracy: 0.0975\n",
      "Epoch 9/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 2.3214 - accuracy: 0.0995 - val_loss: 2.3196 - val_accuracy: 0.0867\n",
      "Epoch 10/1000\n",
      "88/88 [==============================] - 125s 1s/step - loss: 2.3199 - accuracy: 0.1050 - val_loss: 2.3128 - val_accuracy: 0.0975\n",
      "Epoch 11/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 2.3205 - accuracy: 0.0945 - val_loss: 2.3127 - val_accuracy: 0.1096\n",
      "Epoch 12/1000\n",
      "88/88 [==============================] - 125s 1s/step - loss: 2.3187 - accuracy: 0.1021 - val_loss: 3.2391 - val_accuracy: 0.0983\n",
      "Epoch 13/1000\n",
      "88/88 [==============================] - 124s 1s/step - loss: 2.3020 - accuracy: 0.1238 - val_loss: 4.4781 - val_accuracy: 0.0983\n",
      "Epoch 14/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 2.2913 - accuracy: 0.1277 - val_loss: 4.3162 - val_accuracy: 0.1042\n",
      "Epoch 15/1000\n",
      "88/88 [==============================] - 124s 1s/step - loss: 2.2631 - accuracy: 0.1548 - val_loss: 3.2756 - val_accuracy: 0.1079\n",
      "Epoch 16/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 2.2456 - accuracy: 0.1586 - val_loss: 5.3814 - val_accuracy: 0.0975\n",
      "Epoch 17/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 2.2293 - accuracy: 0.1693 - val_loss: 5.4586 - val_accuracy: 0.1017\n",
      "Epoch 18/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 2.2105 - accuracy: 0.1936 - val_loss: 2.6777 - val_accuracy: 0.1025\n",
      "Epoch 19/1000\n",
      "88/88 [==============================] - 119s 1s/step - loss: 2.2105 - accuracy: 0.1846 - val_loss: 4.0763 - val_accuracy: 0.1067\n",
      "Epoch 20/1000\n",
      "88/88 [==============================] - 114s 1s/step - loss: 2.1883 - accuracy: 0.1996 - val_loss: 6.0767 - val_accuracy: 0.1033\n",
      "Epoch 21/1000\n",
      "88/88 [==============================] - 116s 1s/step - loss: 2.1803 - accuracy: 0.2055 - val_loss: 3.3365 - val_accuracy: 0.0867\n",
      "Epoch 22/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 2.1728 - accuracy: 0.2095 - val_loss: 3.4382 - val_accuracy: 0.0996\n",
      "Epoch 23/1000\n",
      "88/88 [==============================] - 126s 1s/step - loss: 2.1696 - accuracy: 0.2075 - val_loss: 3.7125 - val_accuracy: 0.0867\n",
      "Epoch 24/1000\n",
      "88/88 [==============================] - 128s 1s/step - loss: 2.1617 - accuracy: 0.2157 - val_loss: 4.4161 - val_accuracy: 0.1004\n",
      "Epoch 25/1000\n",
      "88/88 [==============================] - 121s 1s/step - loss: 2.1468 - accuracy: 0.2314 - val_loss: 3.8883 - val_accuracy: 0.0867\n",
      "Epoch 26/1000\n",
      "88/88 [==============================] - 114s 1s/step - loss: 2.1381 - accuracy: 0.2368 - val_loss: 3.4292 - val_accuracy: 0.0867\n",
      "Epoch 27/1000\n",
      "88/88 [==============================] - 113s 1s/step - loss: 2.1355 - accuracy: 0.2336 - val_loss: 2.6322 - val_accuracy: 0.1225\n",
      "Epoch 28/1000\n",
      "88/88 [==============================] - 113s 1s/step - loss: 2.1293 - accuracy: 0.2366 - val_loss: 3.9248 - val_accuracy: 0.1025\n",
      "Epoch 29/1000\n",
      "88/88 [==============================] - 114s 1s/step - loss: 2.1259 - accuracy: 0.2361 - val_loss: 2.9797 - val_accuracy: 0.0867\n",
      "Epoch 30/1000\n",
      "88/88 [==============================] - 114s 1s/step - loss: 2.1044 - accuracy: 0.2459 - val_loss: 2.6220 - val_accuracy: 0.0900\n",
      "Epoch 31/1000\n",
      "88/88 [==============================] - 117s 1s/step - loss: 2.1009 - accuracy: 0.2504 - val_loss: 4.1513 - val_accuracy: 0.1154\n",
      "Epoch 32/1000\n",
      "88/88 [==============================] - 121s 1s/step - loss: 2.0675 - accuracy: 0.2607 - val_loss: 3.8255 - val_accuracy: 0.1054\n",
      "Epoch 33/1000\n",
      "88/88 [==============================] - 126s 1s/step - loss: 2.0240 - accuracy: 0.2796 - val_loss: 3.5793 - val_accuracy: 0.1100\n",
      "Epoch 34/1000\n",
      "88/88 [==============================] - 121s 1s/step - loss: 1.9796 - accuracy: 0.2998 - val_loss: 3.3299 - val_accuracy: 0.0975\n",
      "Epoch 35/1000\n",
      "88/88 [==============================] - 114s 1s/step - loss: 1.9789 - accuracy: 0.2982 - val_loss: 3.6263 - val_accuracy: 0.1238\n",
      "Epoch 36/1000\n",
      "88/88 [==============================] - 114s 1s/step - loss: 2.0478 - accuracy: 0.2720 - val_loss: 3.7112 - val_accuracy: 0.0883\n",
      "Epoch 37/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 1.9494 - accuracy: 0.3157 - val_loss: 5.1711 - val_accuracy: 0.0867\n",
      "Epoch 38/1000\n",
      "88/88 [==============================] - 124s 1s/step - loss: 1.9095 - accuracy: 0.3252 - val_loss: 5.0121 - val_accuracy: 0.0871\n",
      "Epoch 39/1000\n",
      "88/88 [==============================] - 125s 1s/step - loss: 1.9123 - accuracy: 0.3268 - val_loss: 2.9061 - val_accuracy: 0.1117\n",
      "Epoch 40/1000\n",
      "88/88 [==============================] - 124s 1s/step - loss: 1.9093 - accuracy: 0.3291 - val_loss: 2.7723 - val_accuracy: 0.1575\n",
      "Epoch 41/1000\n",
      "88/88 [==============================] - 126s 1s/step - loss: 1.8867 - accuracy: 0.3352 - val_loss: 2.7508 - val_accuracy: 0.1354\n",
      "Epoch 42/1000\n",
      "88/88 [==============================] - 115s 1s/step - loss: 1.8926 - accuracy: 0.3343 - val_loss: 2.6564 - val_accuracy: 0.1654\n",
      "Epoch 43/1000\n",
      "88/88 [==============================] - 114s 1s/step - loss: 1.8837 - accuracy: 0.3355 - val_loss: 2.6266 - val_accuracy: 0.1233\n",
      "Epoch 44/1000\n",
      "88/88 [==============================] - 124s 1s/step - loss: 1.8669 - accuracy: 0.3434 - val_loss: 2.6788 - val_accuracy: 0.1754\n",
      "Epoch 45/1000\n",
      "88/88 [==============================] - 124s 1s/step - loss: 1.8581 - accuracy: 0.3504 - val_loss: 4.9957 - val_accuracy: 0.0887\n",
      "Epoch 46/1000\n",
      "88/88 [==============================] - 120s 1s/step - loss: 1.8660 - accuracy: 0.3464 - val_loss: 3.0636 - val_accuracy: 0.1304\n",
      "Epoch 47/1000\n",
      "88/88 [==============================] - 124s 1s/step - loss: 1.8501 - accuracy: 0.3559 - val_loss: 6.2819 - val_accuracy: 0.0862\n",
      "Epoch 48/1000\n",
      "88/88 [==============================] - 125s 1s/step - loss: 1.8493 - accuracy: 0.3486 - val_loss: 4.4856 - val_accuracy: 0.1104\n",
      "Epoch 49/1000\n",
      "88/88 [==============================] - 125s 1s/step - loss: 1.8655 - accuracy: 0.3511 - val_loss: 3.1512 - val_accuracy: 0.1637\n",
      "Epoch 50/1000\n",
      "88/88 [==============================] - 125s 1s/step - loss: 1.8406 - accuracy: 0.3561 - val_loss: 3.9834 - val_accuracy: 0.1100\n",
      "Epoch 51/1000\n",
      "88/88 [==============================] - 124s 1s/step - loss: 1.8266 - accuracy: 0.3562 - val_loss: 4.5389 - val_accuracy: 0.1029\n",
      "Epoch 52/1000\n",
      "88/88 [==============================] - 124s 1s/step - loss: 1.8268 - accuracy: 0.3677 - val_loss: 7.1349 - val_accuracy: 0.0879\n",
      "Epoch 53/1000\n",
      "88/88 [==============================] - 122s 1s/step - loss: 1.8096 - accuracy: 0.3716 - val_loss: 3.3893 - val_accuracy: 0.1408\n",
      "Epoch 54/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 1.8260 - accuracy: 0.3579 - val_loss: 3.3885 - val_accuracy: 0.1321\n",
      "Epoch 55/1000\n",
      "88/88 [==============================] - 118s 1s/step - loss: 1.8239 - accuracy: 0.3623 - val_loss: 5.2256 - val_accuracy: 0.1196\n",
      "Epoch 56/1000\n",
      "88/88 [==============================] - 116s 1s/step - loss: 1.8137 - accuracy: 0.3664 - val_loss: 8.2097 - val_accuracy: 0.0913\n",
      "Epoch 57/1000\n",
      "88/88 [==============================] - 120s 1s/step - loss: 1.8116 - accuracy: 0.3691 - val_loss: 3.9291 - val_accuracy: 0.1154\n",
      "Epoch 58/1000\n",
      "88/88 [==============================] - 115s 1s/step - loss: 1.8029 - accuracy: 0.3720 - val_loss: 5.3066 - val_accuracy: 0.1229\n",
      "Epoch 59/1000\n",
      "88/88 [==============================] - 122s 1s/step - loss: 1.8066 - accuracy: 0.3675 - val_loss: 4.5560 - val_accuracy: 0.1250\n",
      "Epoch 60/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 1.8019 - accuracy: 0.3729 - val_loss: 2.8727 - val_accuracy: 0.1308\n",
      "Epoch 61/1000\n",
      "88/88 [==============================] - 124s 1s/step - loss: 1.8037 - accuracy: 0.3709 - val_loss: 8.3482 - val_accuracy: 0.0858\n",
      "Epoch 62/1000\n",
      "88/88 [==============================] - 124s 1s/step - loss: 1.7878 - accuracy: 0.3793 - val_loss: 4.4134 - val_accuracy: 0.1158\n",
      "Epoch 63/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 1.7951 - accuracy: 0.3764 - val_loss: 7.9335 - val_accuracy: 0.0862\n",
      "Epoch 64/1000\n",
      "88/88 [==============================] - 120s 1s/step - loss: 1.7800 - accuracy: 0.3837 - val_loss: 6.8468 - val_accuracy: 0.1092\n",
      "Epoch 65/1000\n",
      "88/88 [==============================] - 114s 1s/step - loss: 1.7846 - accuracy: 0.3746 - val_loss: 4.8261 - val_accuracy: 0.1125\n",
      "Epoch 66/1000\n",
      "88/88 [==============================] - 110s 1s/step - loss: 1.7775 - accuracy: 0.3814 - val_loss: 3.9848 - val_accuracy: 0.1138\n",
      "Epoch 67/1000\n",
      "88/88 [==============================] - 112s 1s/step - loss: 1.7629 - accuracy: 0.3873 - val_loss: 2.9321 - val_accuracy: 0.1446\n",
      "Epoch 68/1000\n",
      "88/88 [==============================] - 110s 1s/step - loss: 1.7787 - accuracy: 0.3768 - val_loss: 8.3891 - val_accuracy: 0.0942\n",
      "Epoch 69/1000\n",
      "88/88 [==============================] - 110s 1s/step - loss: 1.7576 - accuracy: 0.3907 - val_loss: 9.1926 - val_accuracy: 0.0917\n",
      "Epoch 70/1000\n",
      "88/88 [==============================] - 126s 1s/step - loss: 1.7749 - accuracy: 0.3852 - val_loss: 6.5956 - val_accuracy: 0.1146\n",
      "Epoch 71/1000\n",
      "88/88 [==============================] - 132s 1s/step - loss: 1.7912 - accuracy: 0.3736 - val_loss: 3.2568 - val_accuracy: 0.1163\n",
      "Epoch 72/1000\n",
      "88/88 [==============================] - 130s 1s/step - loss: 1.7732 - accuracy: 0.3816 - val_loss: 7.2238 - val_accuracy: 0.0871\n",
      "Epoch 73/1000\n",
      "88/88 [==============================] - 141s 2s/step - loss: 1.7698 - accuracy: 0.3770 - val_loss: 4.0091 - val_accuracy: 0.0992\n",
      "Epoch 74/1000\n",
      "88/88 [==============================] - 130s 1s/step - loss: 1.7617 - accuracy: 0.3811 - val_loss: 3.1068 - val_accuracy: 0.0933\n",
      "Epoch 75/1000\n",
      "88/88 [==============================] - 128s 1s/step - loss: 1.7506 - accuracy: 0.3907 - val_loss: 7.4909 - val_accuracy: 0.1042\n",
      "Epoch 76/1000\n",
      "88/88 [==============================] - 132s 2s/step - loss: 1.7606 - accuracy: 0.3918 - val_loss: 6.3394 - val_accuracy: 0.0962\n",
      "Epoch 77/1000\n",
      "88/88 [==============================] - 134s 2s/step - loss: 1.7479 - accuracy: 0.3920 - val_loss: 5.7072 - val_accuracy: 0.1183\n",
      "Epoch 78/1000\n",
      "88/88 [==============================] - 133s 2s/step - loss: 1.7447 - accuracy: 0.3952 - val_loss: 8.1960 - val_accuracy: 0.0988\n",
      "Epoch 79/1000\n",
      "88/88 [==============================] - 135s 2s/step - loss: 1.7467 - accuracy: 0.3837 - val_loss: 6.3806 - val_accuracy: 0.0958\n",
      "Epoch 80/1000\n",
      "88/88 [==============================] - 142s 2s/step - loss: 1.7312 - accuracy: 0.3950 - val_loss: 5.3514 - val_accuracy: 0.0887\n",
      "Epoch 81/1000\n",
      "88/88 [==============================] - 134s 2s/step - loss: 1.7390 - accuracy: 0.3880 - val_loss: 3.1267 - val_accuracy: 0.1163\n",
      "Epoch 82/1000\n",
      "88/88 [==============================] - 135s 2s/step - loss: 1.7524 - accuracy: 0.3964 - val_loss: 6.5455 - val_accuracy: 0.0887\n",
      "Epoch 83/1000\n",
      "88/88 [==============================] - 134s 2s/step - loss: 1.7372 - accuracy: 0.4005 - val_loss: 6.0941 - val_accuracy: 0.0975\n",
      "Epoch 84/1000\n",
      "88/88 [==============================] - 136s 2s/step - loss: 1.7358 - accuracy: 0.3966 - val_loss: 9.3671 - val_accuracy: 0.0879\n",
      "Epoch 85/1000\n",
      "88/88 [==============================] - 133s 2s/step - loss: 1.7383 - accuracy: 0.4005 - val_loss: 2.5937 - val_accuracy: 0.1983\n",
      "Epoch 86/1000\n",
      "88/88 [==============================] - 134s 2s/step - loss: 1.7214 - accuracy: 0.4080 - val_loss: 8.6052 - val_accuracy: 0.0929\n",
      "Epoch 87/1000\n",
      "88/88 [==============================] - 135s 2s/step - loss: 1.7324 - accuracy: 0.3941 - val_loss: 6.8411 - val_accuracy: 0.0908\n",
      "Epoch 88/1000\n",
      "88/88 [==============================] - 138s 2s/step - loss: 1.7346 - accuracy: 0.4004 - val_loss: 8.9887 - val_accuracy: 0.0858\n",
      "Epoch 89/1000\n",
      "88/88 [==============================] - 130s 1s/step - loss: 1.7309 - accuracy: 0.4030 - val_loss: 7.6061 - val_accuracy: 0.1071\n",
      "Epoch 90/1000\n",
      "88/88 [==============================] - 135s 2s/step - loss: 1.7442 - accuracy: 0.3896 - val_loss: 7.3577 - val_accuracy: 0.0992\n",
      "Epoch 91/1000\n",
      "88/88 [==============================] - 138s 2s/step - loss: 1.7145 - accuracy: 0.3998 - val_loss: 3.3315 - val_accuracy: 0.1033\n",
      "Epoch 92/1000\n",
      "88/88 [==============================] - 154s 2s/step - loss: 1.7360 - accuracy: 0.3971 - val_loss: 3.7943 - val_accuracy: 0.1104\n",
      "Epoch 93/1000\n",
      "88/88 [==============================] - 140s 2s/step - loss: 1.7372 - accuracy: 0.3973 - val_loss: 7.8502 - val_accuracy: 0.1008\n",
      "Epoch 94/1000\n",
      "88/88 [==============================] - 142s 2s/step - loss: 1.7240 - accuracy: 0.3993 - val_loss: 3.7437 - val_accuracy: 0.1354\n",
      "Epoch 95/1000\n",
      "88/88 [==============================] - 133s 2s/step - loss: 1.7285 - accuracy: 0.3950 - val_loss: 5.4467 - val_accuracy: 0.1021\n",
      "Epoch 96/1000\n",
      "88/88 [==============================] - 120s 1s/step - loss: 1.7219 - accuracy: 0.3986 - val_loss: 3.3207 - val_accuracy: 0.0958\n",
      "Epoch 97/1000\n",
      "88/88 [==============================] - 121s 1s/step - loss: 1.7239 - accuracy: 0.4002 - val_loss: 7.7466 - val_accuracy: 0.0946\n",
      "Epoch 98/1000\n",
      "88/88 [==============================] - 120s 1s/step - loss: 1.7085 - accuracy: 0.4084 - val_loss: 9.0895 - val_accuracy: 0.0904\n",
      "Epoch 99/1000\n",
      "88/88 [==============================] - 119s 1s/step - loss: 1.7059 - accuracy: 0.4104 - val_loss: 3.1689 - val_accuracy: 0.0983\n",
      "Epoch 100/1000\n",
      "88/88 [==============================] - 119s 1s/step - loss: 1.7012 - accuracy: 0.4157 - val_loss: 3.4687 - val_accuracy: 0.1383\n",
      "Epoch 101/1000\n",
      "88/88 [==============================] - 120s 1s/step - loss: 1.7131 - accuracy: 0.4055 - val_loss: 3.7773 - val_accuracy: 0.1396\n",
      "Epoch 102/1000\n",
      "88/88 [==============================] - 119s 1s/step - loss: 1.7173 - accuracy: 0.4018 - val_loss: 3.3722 - val_accuracy: 0.1408\n",
      "Epoch 103/1000\n",
      "88/88 [==============================] - 119s 1s/step - loss: 1.7085 - accuracy: 0.4100 - val_loss: 2.8318 - val_accuracy: 0.1287\n",
      "Epoch 104/1000\n",
      "88/88 [==============================] - 119s 1s/step - loss: 1.7119 - accuracy: 0.4118 - val_loss: 2.7423 - val_accuracy: 0.1517\n",
      "Epoch 105/1000\n",
      "88/88 [==============================] - 119s 1s/step - loss: 1.7034 - accuracy: 0.4129 - val_loss: 2.9377 - val_accuracy: 0.1267\n",
      "Epoch 106/1000\n",
      "88/88 [==============================] - 117s 1s/step - loss: 1.6997 - accuracy: 0.4132 - val_loss: 3.3571 - val_accuracy: 0.1587\n",
      "Epoch 107/1000\n",
      "88/88 [==============================] - 118s 1s/step - loss: 1.6960 - accuracy: 0.4171 - val_loss: 3.2384 - val_accuracy: 0.1308\n",
      "Epoch 108/1000\n",
      "88/88 [==============================] - 116s 1s/step - loss: 1.6865 - accuracy: 0.4139 - val_loss: 6.5263 - val_accuracy: 0.1021\n",
      "Epoch 109/1000\n",
      "88/88 [==============================] - 120s 1s/step - loss: 1.6853 - accuracy: 0.4166 - val_loss: 4.3097 - val_accuracy: 0.1158\n",
      "Epoch 110/1000\n",
      "88/88 [==============================] - 123s 1s/step - loss: 1.7132 - accuracy: 0.4129 - val_loss: 4.3668 - val_accuracy: 0.1079\n",
      "Epoch 111/1000\n",
      "88/88 [==============================] - 121s 1s/step - loss: 1.6980 - accuracy: 0.3982 - val_loss: 4.6549 - val_accuracy: 0.0967\n",
      "Epoch 112/1000\n",
      "88/88 [==============================] - 121s 1s/step - loss: 1.6948 - accuracy: 0.4125 - val_loss: 4.3100 - val_accuracy: 0.1079\n",
      "Epoch 113/1000\n",
      "88/88 [==============================] - 120s 1s/step - loss: 1.6894 - accuracy: 0.4161 - val_loss: 2.7745 - val_accuracy: 0.1317\n",
      "Epoch 114/1000\n",
      "88/88 [==============================] - 120s 1s/step - loss: 1.7035 - accuracy: 0.4045 - val_loss: 6.8384 - val_accuracy: 0.1079\n",
      "Epoch 115/1000\n",
      "88/88 [==============================] - 128s 1s/step - loss: 1.6868 - accuracy: 0.4220 - val_loss: 5.4952 - val_accuracy: 0.0983\n",
      "Epoch 116/1000\n",
      "88/88 [==============================] - 133s 2s/step - loss: 1.7073 - accuracy: 0.4159 - val_loss: 6.4784 - val_accuracy: 0.1021\n",
      "Epoch 117/1000\n",
      "88/88 [==============================] - 154s 2s/step - loss: 1.6969 - accuracy: 0.4127 - val_loss: 3.1673 - val_accuracy: 0.1096\n",
      "Epoch 118/1000\n",
      "88/88 [==============================] - 145s 2s/step - loss: 1.6813 - accuracy: 0.4198 - val_loss: 7.0462 - val_accuracy: 0.1008\n",
      "Epoch 119/1000\n",
      "88/88 [==============================] - 119s 1s/step - loss: 1.6972 - accuracy: 0.4129 - val_loss: 7.9452 - val_accuracy: 0.0971\n",
      "Epoch 120/1000\n",
      "47/88 [===============>..............] - ETA: 52s - loss: 1.6961 - accuracy: 0.4099"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_resized, y_train, \n",
    "                    validation_data=(X_valid_resized, y_valid), \n",
    "                    epochs=1000, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Henri\\python\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model.h5\")  # Saves in HDF5 format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \n\u001b[1;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m history\u001b[38;5;241m.\u001b[39mhistory:  \n\u001b[0;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)  \n",
    "plt.plot(history.history['loss'], marker='o', linestyle='none', label='Training Loss')\n",
    "if 'val_loss' in history.history:  \n",
    "    plt.plot(history.history['val_loss'], marker='o', linestyle='none', label='Validation Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], marker='o', linestyle='none', label='Training Accuracy')\n",
    "if 'val_accuracy' in history.history:  \n",
    "    plt.plot(history.history['val_accuracy'], marker='o', linestyle='none', label='Validation Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
